---
title: 'Tipología y ciclo de vida de los datos: ¿Cómo realizar la limpieza y análisis de datos?'
author: "Autores: William Gabriel Granda Betancourt y Oscar Augusto Diaz Triana."
date: "Mayo 2023"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
      in_header: 75.584-PEC-header.html
  pdf_document:
    highlight: zenburn
    toc: yes
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval=T, echo=T)
library(dplyr)
library(ggplot2)
library(tidyr)
library(showtext)
library(gridExtra)
library(kableExtra)
```

------------------------------------------------------------------------

# Descripción del dataset

------------------------------------------------------------------------

Vamos a trabajar con el conjunto de datos [Heart Attack Analysis & Prediction dataset](https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-predictiondataset), el cual se encuentra disponible en Kaggle.

```{r message= FALSE, warning=FALSE}
data<-read.csv("./heart.csv",header=T,sep=",")
```

Empezaremos haciendo un análisis sobre el número de registros y número de variables que contiene el dataset.

El conjunto de datos contiene `r data %>% nrow()` registros u observaciones y `r data %>% ncol()` variables. Contamos con las siguientes variables:

```{r}
str(data)
```

-   **age**: Edad del paciente. Es una variable numérica.
-   **sex**: Sexo del paciente.
    -   1 = hombre,
    -   0 = mujer.
-   **exng**: Angina producida por ejercicio. Es un variable categórica y toma los siguientes valores:
    -   1, si se posee la molestia
    -   0, si no.

(La angina es un dolor o molestia en el pecho producida cuando una zona del músculo cardíaco no recibe suficiente cantidad de sangre oxigenada).

-   **caa**: Número de vasos principales coloreados por fluroscopia. Es una variable numérica discreta y toma los siguientes valores: (0-3).

-   **cp**: Tipo de dolor toráxico. Es una variable categórica que toma los siguientes valores:

    -   1: angina típica,
    -   2: angina atípica,
    -   3: dolor no anginoso,
    -   0: asintomático.

-   **trtbps**: Presión arterial en reposo (en $mm Hg$).

-   **chol**: Colesterol en $mg/dl$ obtenido a través del sensor BMI.

-   **fbs**: Azúcar en sangre en ayunas $> 120 \; mg/dl$. Es una variable categórica, que toma los siguientes valores:

    -   1 = verdadero,
    -   0 = falso.

-   **restecg**: Resultados electrocardiográficos en reposo. Es un variable categórica que toma los siguientes valores:

    -   0: normal,
    -   1: Indica si el paciente tiene anomalías en la onda ST-T (inversiones de la onda T y/o elevación o depresión del $ST > 0.05\; mV$)
    -   2: Indica si el paciente muestra hipertrofia ventricular izquierda probable o definitiva, según los criterios de Estes.

-   **thalachh**: Frecuencia cardíaca máxima alcanzada. Es una variable numérica continua.

-   **oldpeak**: Depresión del ST inducida por el ejercicio en relación con el reposo. Es una variable numérica continua.

-   **slp**: Pendiente de un segmento de electrocardiograma. Es una variable categórica que toma los siguientes valores:

    -   0: pendiente descendente,
    -   1: plano,
    -   2: pendiente ascendente.

-   **thall**: Indica los resultados de prueba de esfuerzo con talio, la muestra qué tan bien fluye la sangre hacia el músculo cardíaco, tanto en reposo como en actividad. Es una variable categórica y toma los siguientes valores:

    -   1: normal,\
    -   2: defecto fijo,
    -   3: defecto reversible.

-   **output**: Es nuestra variable binaria a predecir, toma los siguientes valores:

    -   1 = más posibilidades de ataque al corazón,
    -   0 = menos posibilidades de ataque al corazón.

**Problema a resolver**:

De este modo, podemos concluir que el conjunto de datos contiene información sobre pacientes y las posibilidades de sufrir un infarto. El problema a resolver consiste en determinar aquellas características que influyen en que una persona sea más propensa a sufrir un ataque al corazón, para resolver este problema se podría implementar un modelo de clasificación.

Este juego de datos es importante porque predecir con antelación que una persona sea propensa a sufrir un ataque cardíaco permitiría a los especialistas médicos intervenir a tiempo y tomar medidas tempranas para reducir este riesgo. De este modo se podría salvar vidas y mejorar la salud cardiovascular de la población de estudio.

# Limpieza de datos

Vamos a emplear todas las variables numéricas y categóricas con la intención de determinar que variables influyen en que una persona sea más propensa a sufrir un ataque al corazón.

Al aplicar la función str() pudimos notar que ciertas variables categóricas fueron identificadas como numéricas, por ello, vamos a transformarlas al tipo factor:

```{r, warning=FALSE, message=FALSE}
data<- data %>% mutate(sex = as.factor(sex), cp = as.factor(cp), thall = as.factor(thall), fbs = as.factor(fbs), 
                       restecg = as.factor(restecg), exng = as.factor(exng), slp = as.factor(slp), thall = as.factor(thall),
                       output = as.factor(output))
```

En primer lugar, vamos a determinar si existen valores perdidos para cada variable:

```{r, warning=FALSE, message=FALSE}
sapply(data, function(x) {sum(is.na(x))})
```

De este modo podemos obsevar que no existen valores atípicos.

Determinemos si existen valores duplicados:

```{r, warning=FALSE, message=FALSE}
data[duplicated(data),]
```

Con lo cual, existen dos filas duplicadas, la función unique() nos permite resolver este problema:

```{r, warning=FALSE, message=FALSE}
data<- data %>% unique()
```

De este modo, nuestro juego de datos posee `r data %>% nrow()` observaciones.

Ahora, vamos a analizar cada una variables, para ello, presentamos sus estadísticos:

```{r, warning=FALSE, message=FALSE}
summary(data)
```

## Variables numéricas

Para complementar esta información vamos a presentar la distribución de las variables:

```{r, warning=FALSE, message=FALSE, fig.align='center'}
data %>% select(is.numeric) %>% gather(metric, value) %>% ggplot(aes(value, fill = metric)) +
                                geom_density(show.legend = FALSE) + facet_wrap(~ metric, scales = "free", ncol = 2) + 
                                theme(strip.text=element_text(face='bold', size=14, hjust=0, color='white'),
                                strip.background=element_rect(fill='black'))

```

Se tienen las siguientes observaciones:

-   **age**: La edad promedio de los pacientes es $54$ años, la edad mínima es $29$ años y la edad máxima es de $77$ años. Además, el $75\%$ de los pacientes es menor a $61$ años. Con respecto a la distribución de la variable podemos notar que es bimodal, es decir, presenta dos modas.

-   **caa**: El valor mínimo de esta variable es 0 y el valor máximo es 4. Como podemos notar la distribución de la variables es sesgada a la izquierda. El $75\%$ de los pacientes ha registrado entre 0 y 1 vasos colorados por fluroscopia.

-   **chol**: El valor mínimo del colestero es $94$ y el valor máximo es $200$, además, el $75\%$ de los pacientes tiene un colesterol inferior a $274.8$. Podemos notar que existen pocos valores en la cola derecha de la distribución los cuales pueden corresponder a valores atípicos.

-   **oldpeak**: El valor mínimo de la depresión del segmento ST es $0$ y el valor máximo es de $6.2$. El $75\%$ de lo clientes posee un valor de depresión del segmento ST menor a $1.6$. La distribución de esta variable está acumulada a la izquierda.

-   **thalachh**: El valor mínimo de a frecuencia cardíaca máxima alcanzada es de $71$ y el valor máximo es de $202$. Además, el $75\%$ de los pacientes tiene una frecuencia máxima alcanza menor a $166$. La distribución de esta variable es sesgada a la derecha.

-   **trtbps**: El valor mínimo de la presión arterial es de $94$ y el valor máximo es de $200$. También podemos afirmar que el $75\%$ de los pacientes tiene una presión arterial menor o igual a $130$. Podemos notar que existen pocos valores en la cola derecha de la distribución, los cuales podrían corresponder a valores atípicos.

Ahora, analicemos los valores atípicos, para lo cual emplearemos el diagrama de cajas o boxplot:

```{r, warning=FALSE, message=FALSE, fig.align='center'}
data %>% select(is.numeric) %>% gather(metric, value) %>% ggplot(aes(value, fill = metric)) +
                                geom_boxplot(show.legend = FALSE) + facet_wrap(~ metric, scales = "free", ncol = 2) + 
                                theme(strip.text=element_text(face='bold', size=14, hjust=0, color='white'),
                                strip.background=element_rect(fill='black'))

```

-   **caa**: La variable caa posee dos valores atípicos $3$ y $4$, no obstante en la definición de esta variable se especifica que su dominio es $(0-3)$, por lo que el único valor atípico es $4$. Vamos a reemplazar estos valores atípicos por el valor máximo de esta variable que es $3$.

-   Para las variables **chol**, **oldpeak** y **trtbps** vamos a reemplazar los valores atípicos por la mediana de cada una de las variables, debido la media está sesgada por los valores atípicos.

```{r, warning=FALSE, message=FALSE}

## Valores atípicos para chol: 

q1Chol<- quantile(data$chol,0.25)
q3Chol<- quantile(data$chol,0.75)
IQR<- q3Chol-q1Chol
medianChol<- median(data$chol)
atipicosChol<- sort(data[data$chol > q3Chol+1.5*IQR,]$chol)

## Valores atípicos para oldepeak: 

q1oldpeak<- quantile(data$oldpeak,0.25)
q3oldpeak<- quantile(data$oldpeak,0.75)
IQRoldpeak<- q3oldpeak-q1oldpeak
medianoldpeak<- median(data$oldpeak)
atipicosoldpeak<- sort(data[data$oldpeak > q3oldpeak+1.5*IQRoldpeak,]$oldpeak)

## Valores atípicos para trtbps: 

q1trtbps<- quantile(data$trtbps,0.25)
q3trtbps<- quantile(data$trtbps,0.75)
IQRtrtbps<- q3trtbps-q1trtbps
mediantrtbps<- median(data$trtbps)
atipicostrtbps<- sort(data[data$trtbps > q3trtbps+1.5*IQRtrtbps,]$trtbps)


data<- data %>% mutate(caa = ifelse(caa >= 4, 3, caa), chol = ifelse(chol %in% atipicosChol,medianChol, chol), 
                       oldpeak = ifelse(oldpeak %in% atipicosoldpeak , medianoldpeak, oldpeak), 
                       trtbps = ifelse(trtbps %in% atipicostrtbps, mediantrtbps, trtbps))



```

De este modo, podemos observar que no existen valores atípicos:

```{r, warning=FALSE, message=FALSE, fig.align='center'}
data %>% select(is.numeric) %>% gather(metric, value) %>% ggplot(aes(value, fill = metric)) +
                                geom_boxplot(show.legend = FALSE) + facet_wrap(~ metric, scales = "free", ncol = 2) + 
                                theme(strip.text=element_text(face='bold', size=14, hjust=0, color='white'),
                                strip.background=element_rect(fill='black'))
```

## Variables categóricas

Para las variables categóricas vamos a presentar su diagrama de frecuencias:

```{r, warning=FALSE, message=FALSE, fig.align='center', fig.height=15, fig.width=10}
plotSex<- ggplot(data,aes(sex, fill = sex)) + geom_bar() + geom_text(aes(label = paste0( round(..count../sum(..count..)*100,2) , "%")), stat = "count",position = position_stack(vjust=0.5)) + labs(x="Sex", y="Pacientes")+ guides(fill=guide_legend(title="")) + theme(legend.position="none")
#
plotcp<- ggplot(data,aes(cp, fill = cp)) + geom_bar() + geom_text(aes(label = paste0( round(..count../sum(..count..)*100,2) , "%")), stat = "count",position = position_stack(vjust=0.5)) + labs(x="Tipo de dolor toráxico", y="Pacientes") + guides(fill=guide_legend(title="")) + theme(legend.position="none")
#
plotfbs<- ggplot(data,aes(fbs, fill = fbs)) + geom_bar() + geom_text(aes(label = paste0( round(..count../sum(..count..)*100,2) , "%")), stat = "count",position = position_stack(vjust=0.5)) + labs(x="Azúcar en sangre", y="Pacientes") + guides(fill=guide_legend(title="")) + theme(legend.position="none")
#
plotthall<- ggplot(data,aes(thall, fill = thall)) + geom_bar() + geom_text(aes(label = paste0( round(..count../sum(..count..)*100,2) , "%")), stat = "count",position = position_stack(vjust=0.5)) + labs(x="Azúcar en la sangre", y="Pacientes") + guides(fill=guide_legend(title="")) + theme(legend.position="none")
#
plotrestecg<- ggplot(data,aes(restecg, fill = restecg)) + geom_bar() + geom_text(aes(label = paste0( round(..count../sum(..count..)*100,2) , "%")), stat = "count",position = position_stack(vjust=0.5)) + labs(x="Resultados electrocardiográficos", y="Pacientes") + guides(fill=guide_legend(title="")) + theme(legend.position="none")
#
plotexng<- ggplot(data,aes(exng, fill = exng)) + geom_bar() + geom_text(aes(label = paste0( round(..count../sum(..count..)*100,2) , "%")), stat = "count",position = position_stack(vjust=0.5)) + labs(x="Angina", y="Pacientes") + guides(fill=guide_legend(title="")) + theme(legend.position="none")
# 
plotslp<- ggplot(data,aes(slp, fill = slp)) + geom_bar() + geom_text(aes(label = paste0( round(..count../sum(..count..)*100,2) , "%")), stat = "count",position = position_stack(vjust=0.5)) + labs(x="Pendiente segmento electrocardiograma", y="Pacientes") + guides(fill=guide_legend(title="")) + theme(legend.position="none")
# 
plotthall<- ggplot(data,aes(thall, fill = thall)) + geom_bar() + geom_text(aes(label = paste0( round(..count../sum(..count..)*100,2) , "%")), stat = "count",position = position_stack(vjust=0.5)) + labs(x="Prueba de esfuerzo", y="Pacientes") + guides(fill=guide_legend(title="")) + theme(legend.position="none")
# 
plotoutput<- ggplot(data,aes(output, fill = output)) + geom_bar() + geom_text(aes(label = paste0( round(..count../sum(..count..)*100,2) , "%")), stat = "count",position = position_stack(vjust=0.5)) + labs(x="Output", y="Pacientes") + guides(fill=guide_legend(title="")) + theme(legend.position="none")

grid.arrange(plotSex, plotcp, plotfbs, plotthall, plotrestecg, plotexng, plotslp, plotslp, plotthall, plotoutput, ncol = 2)
```

Se tienen las siguientes observaciones:

-   **sex**: El $68.21\%$ de los pacientes son hombres, mientras que el $31.79\%$ son mujeres.
-   **cp**: El $43.25\%$ de los pacientes es asintomático, el $16.56\%$ posee angina típica, el $28.48\%$ posee angina atípica y el $7.62\%$ tiene dolor no anginoso.
-   **fbs**: El $85.15\%$ de los pacientes no posee azúcar en sangre en ayunas superior a $120 \; mg/dl$, mientras que el $14.85\%$ de los pacientes si posee niveles de azúcar superiores.
-   **thall**: El $85.1\%$ de los pacientes no registra azúcar en la sangre mayor a $>120\;mg/dl$, mientras que el $14.9\%$ sí.
-   **restecg**: El $48.68\%$ de los pacientes posee resultados electrocardiográficos normales, el $50\%$ de los pacientes posee anomalías en la onda ST-T y finalmente, el $1.32\%$ de los pacientes muestra hipertrofia ventricular izquierda probable o definitiva.
-   **exng**: El $67.22\%$ de los pacientes no posee el dolor de angina, mientras que el $32.78\%$ sí lo posee.
-   **slp**: El $6.95\%$ posee una pendiente descendiente de segmento de electrocardiograma, el $46.36\%$ posee una pendiente plana y el $46.69\%$ posee una pendiente ascendente.
-   **thall**: Esta variable solamente debería tomar tres valores, por lo que el valor de cero corresponde a un valor perdido, reemplazaremos este valor por $2$, que es el valor que más se repite. El $5.96\%$ de los pacientes posee un defecto fijo, el $54.94\%$ de los pacientes dio un resultado normal y el $38.74\%$ tiene un defecto reversible.

```{r, warning=FALSE, message=FALSE}
data<- data %>% mutate(thall = if_else(thall == "0", "2", thall) )
```

-   **output**: El $45.7\%$ de los pacientes tiene menos probabilidades de sufrir un ataque al corarón, mientras que el $54.3\%$ de los pacientes tiene más probabilidades de sufrir un ataque al corazón.

## Correlaciones

Em primer lugar, para determinar el tipo de prueba para analizar las correlaciones de las variables numéricas vamos a verificar si nuestras variables tienen o no distribuciones normales. Para ello, emplearemos la prueba de Shapiro-Wilk, la cual contrasta las siguientes hipótesis:

$$\begin{cases} H_0: \text{Los datos siguen distribución normal.} \\ H_1: \text{Los datos no siguen una ditribución normal.} \; \end{cases}$$

**age**

```{r}
shapiro.test(data$age)
```

Considerando un nivel de confianza $\alpha = 0.05$ se rechaza la hipótesis nula, y podemos concluir que los datos no siguen una distribución normal.

**trtbps**

```{r}
shapiro.test(data$trtbps)
```

Considerando un nivel de confianza $\alpha = 0.05$ se rechaza la hipótesis nula, y podemos concluir que los datos no siguen una distribución normal.

**chol**

```{r}
shapiro.test(data$chol)
```

Considerando un nivel de confianza $\alpha = 0.05$ no se rechaza la hipótesis nula, y podemos concluir que los datos siguen una distribución normal.

**thalachh**:

```{r}
shapiro.test(data$thalachh)
```

Para un nivel de confianza $\alpha = 0.05$ se rechaza la hipótesis nula, y podemos concluir que los datos no siguen una distribución normal.

**oldpeak**:

```{r}
shapiro.test(data$oldpeak)
```

De igual forma si se considera un nivel de confianza $\alpha = 0.05$ se rechaza la hipótesis nula, y podemos concluir que los datos no siguen una distribución normal.

Dado que tres de las cuatro variables numéricas no siguen una distribución normal, vamos a emplear la prueba de correlación de Spearman, la cual es una alternativa no paramétrica cuando las variables no son normales.

```{r, warning=FALSE, message=FALSE, fig.align='center'}
library(corrplot)

correlaciones<- cor(data %>% select(age, trtbps, chol, thalachh, oldpeak), method = "spearman" ) 
corrplot(correlaciones, method="color",tl.col="black", tl.srt=30, order = "AOE",
number.cex=0.75,sig.level = 0.01, addCoef.col = "black")
```

No observamos fuertes correlaciones positivas o negativas entre las variables, no obtante, vamos a aplicar pruebas de hipótesis para determinar si la correlación es significativamente distinta de cero. Para lo cual, emplearemos la prueba de Spearman, la cual contrasta las hipótesis:

$$\begin{cases} H_0: \text{Las variables}\; X\; \text{y} \; Z\; \text{son independientes}\\ H_1: \text{Las variables}\; X\; \text{y} \; Z\; \text{no son independientes}  \end{cases}$$ **thalachh vs oldpeak**

```{r, warning=FALSE, message=FALSE}
cor.test(data$thalachh, data$oldpeak, method="spearman")
```

Para un nivel de confianza $\alpha = 0.05$, se rechaza la hipótesis nula y podemos concluir que la correlación entre las variables **thalachh** y **oldpeak** es de $-0.417$, no obstante, este no es un valor elevado.

**thalachh vs age**

También aplicaremos la prueba a las variables **thalachh** y \*\*age\*:

```{r, warning=FALSE, message=FALSE}
cor.test(data$thalachh, data$age, method="spearman")
```

De igual forma, considerando un nivel de confianza $\alpha = 0.05$, se rechaza la hipótesis nula y podemos concluir que la correlación entre las variables **thalachh** y **age** es de $-0.393$, el cual no es un valor elevado.

**thalachh vs trtbps**

```{r, warning=FALSE, message=FALSE}
cor.test(data$thalachh, data$trtbps, method="spearman")
```

Con un nivel de confianza $\alpha = 0.05$, dado que $p-valor > \alpha$, no se rechaza la hipótesis nula y podemos concluir que las variables **thalachh** y **trtbps** son independientes.

**thalachh vs chol**

```{r, warning=FALSE, message=FALSE}
cor.test(data$thalachh, data$chol, method="spearman")
```

De igual forma, con un nivel de confianza $\alpha = 0.05$, dado que $p-valor > \alpha$, no se rechaza la hipótesis nula y podemos concluir que las variables **thalachh** y **trtbps** son independientes.

# Comparación entre grupos

## Variables numéricas

En primer, lugar vamos a estudiar gráficamente el comportamiento de las variables **age**, **trtbps**, **thalachh** y **oldpeak** con respecto a la variable **output**, para lo cual, vamos a diagramas de cajas:

```{r, warning=FALSE, message=FALSE, fig.align='center'}
data %>% select(age, trtbps, chol, thalachh, oldpeak, output) %>% 
               gather(metric, value, 1:5) %>% ggplot(aes(value, group = output, colour = output)) +
  geom_boxplot() +
  facet_wrap(~ metric, scales = "free", ncol = 2) + theme(strip.text=element_text(face='bold', size=14, hjust=0, color='white'),
        strip.background=element_rect(fill='black'))
```

Podemos notar que existen diferencias significativas de las variables **age**, **chol**, **oldpeak** y **thalachh** con respecto a la variable **ouput**. Vamos a comprobar estas hipótesis aplicando pruebas estadísticas.

Para ello, en primer lugar, como pudimos observar anteriormente solamente la variable **chol** sigue una distribución normal por lo que vamos a aplicar la transformación de Box - Cox para el resto de variables:

```{r, warning=FALSE, message=FALSE}
library(DescTools)

dataT<- data %>% mutate(ageT = BoxCox(age, lambda = BoxCoxLambda(age)), trtbpsT = BoxCox(trtbps, lambda = BoxCoxLambda(trtbps)), 
                       thalachhT = BoxCox(thalachh, lambda = BoxCoxLambda(thalachh)), oldpeakT = BoxCox(oldpeak, lambda = BoxCoxLambda(oldpeak)) )

```

De este modo, aplicamos la prueba de Shapiro-Wilk a las variables transformadas:

**age**

```{r}
shapiro.test(dataT$ageT)
```

Considerando un nivel de confianza $\alpha = 0.05$ se rechaza la hipótesis nula, y podemos concluir que los datos no siguen una distribución normal.

**trtbps**

```{r}
shapiro.test(dataT$trtbpsT)
```

Considerando un nivel de confianza $\alpha = 0.05$ se rechaza la hipótesis nula, y podemos concluir que los datos no siguen una distribución normal.

**thalachh**:

```{r}
shapiro.test(dataT$thalachhT)
```

Para un nivel de confianza $\alpha = 0.05$, dado que $p-valor > \alpha$, no se rechaza la hipótesis nula, y podemos concluir que los datos siguen una distribución normal.

**oldpeak**:

```{r}
shapiro.test(dataT$oldpeakT)
```

Considerando un nivel de confianza $\alpha = 0.05$ se rechaza la hipótesis nula, y podemos concluir que los datos no siguen una distribución normal.

De este modo, vamos a aplicar la prueba de homocedasticidad a la variable **chol** y a la variable transformada **thalachh**:

**chol**:

```{r, warning=FALSE, message=FALSE}
library(car)

leveneTest(chol ~ output, data = dataT)
```

Al nivel de significancia $\alpha = 0.05$ no rechazamos la hipótesis nula, es decir, la varianza de la variable **chol** con respecto a la variable **output** es homogénea, por lo cual podemos aplicar la prueba t de Student.

```{r}
t.test(chol ~ output, data = dataT)
```

En este caso, el $p-valor$ es mayor al nivel de significancia $\alpha = 0.05$. Por lo cual, no se rechaza la hipótesis nula, es decir, no se observan diferencias significativas entre el colesterol de las personas menos propensas a sufrir un ataque cardíaco y las personas más propensas a sufrir un ataque cardíaco.

**thalachhT**:

```{r, warning=FALSE, message=FALSE}
leveneTest(thalachhT ~ output, data = dataT)
```

Al nivel de significancia $\alpha = 0.05$ no rechazamos la hipótesis nula, es decir, las varianzas son homogéneas, por lo cual podemos aplicar la prueba t de Student.

```{r}
t.test(thalachhT ~ output, data = dataT)
```

En este caso, el $p-valor$ es menor al nivel de significancia $\alpha = 0.05$. Por lo cual, se rechaza la hipótesis nula, es decir, se observan diferencias significativas de la frecuencia máxima alcanzada entre entre las personas menos propensas a sufrir un ataque cardíaco y las personas más propensas a sufrir un ataque cardíaco. De hecho, podemos ver que el promedio estimado del grupo de personas menos propensas es menor al grupo de las personas más propensas.

Para el resto de variables numéricas vamos a trabajar con las variables originales, dado que las tranformaciones de Box y Cox de estas variables no cumplieron el supuesto de normalidad y aplicaremos la prueba de Wilcoxon:

**age**

```{r, warning=FALSE, message=FALSE}
wilcox.test(age ~ output, data = data)
```

En este caso el $p-valor$ es menor al nivel de significancia $\alpha = 0.05$, por lo cual, sí se observan diferencias estadísticamente significativas en la edad de los pacientes con respecto a la variable **output**.

**chol**

```{r}
wilcox.test(chol ~ output, data = data)
```

El $p-valor$ es menor al nivel de significancia $\alpha = 0.05$, por lo cual, sí se observan diferencias estadísticamente significativas en el nivel del colesterol entre las pesonas menos probables y más probables a sufir un ataque al corazón.

**trtbps**

```{r, warning=FALSE, message=FALSE}
wilcox.test(trtbps ~ output, data = data)
```

En este caso el $p-valor$ es mayor al nivel de significancia $\alpha = 0.05$, por lo cual, no se observan diferencias estadísticamente significativas en la presión arterial entre los pacientes más propensos y menos propensos a sufrir ataques cardíacos.

**oldpeakT**

```{r, warning=FALSE, message=FALSE}
wilcox.test(oldpeak ~ output, data = data)
```

En este caso el $p-valor$ es menor al nivel de significancia $\alpha = 0.05$, por lo cual, sí se observan diferencias estadísticamente significativas en la depresión del segmento ST de los pacientes más probables y menos probables a sufir ataques cardíacos.

## Variables categóricas

En esta sección vamos a determinar si existen diferencias significativas de las variables categóricas **sex**, **cp**, **thall**, **restecg**, **exng**, **slp**, **thall** entre los grupos definidos por la variable categórica **output**. En primer lugar, vamos a presentar diagramas de frecuencias de cada una de estas variables con respecto a la variable **output**, lo cual nos permitirá formar una idea sobre el comportamiento de estas variables.

Para ello, vamos a emplear el test $\chi^2$, el cual plantea la siguiente prueba de hipótesis:

$$\begin{cases} H_0: \text{La variable}\; X\; \text{es independiente a la variable}\; Y. \\ H_1: \text{Las variables}\; X\; \text{y} \; Y\; \text{están asocidadas}. \; \end{cases}$$

**sex** y **output**:

```{r}
prop.table(table(data$sex, data$output), margin = 1)
```

-   Podemos notar que el $75\%$ de las mujeres son más propensas a sufrir un ataque cardíaco, mientras que en los hombres solamente el $49.83\%$ lo son.

Con la prueba $\chi^2$ se obtienen los siguientes resultados:

```{r, warning=FALSE, message=FALSE}
outputsex<- table(data$sex, data$output)
chisq.test(outputsex)
```

Considerando un nivel de significancia del $\alpha = 0.05$, dado que $p-valor < \alpha$, podemos rechazar la hipótesis nula y concluir que existe una asociación significativa entre las variables **sex** y **output**. Es decir, podemos afirmar que la distribución de género difiere significativamente entre los grupos de **output**.

**cp** y **output**

```{r, warning=FALSE, message=FALSE}
prop.table(table(data$cp, data$output), margin = 1)
```

-   Solamente para los pacientes asintomáticos la tasa de personas sanas es mayor a la tasa de personas propensas a sufrir una enfermedad. En este caso, la tasa de personas sanas es de $72.72\%$.

-   En las categorías angina típica, angina atípica y dolor no anginoso, la tasa de personas sanas es menor, siendo estas de $18\%$, $20.69\%$ y $30.43\%$, respectivamente.

Aplicado la prueba $\chi^2$, tenemos que:

```{r, warning=FALSE, message=FALSE}
outputcp<- table(data$cp, data$output)
chisq.test(outputcp)
```

Para un nivel de significancia del $\alpha = 0.05$, dado que $p-valor < \alpha$, podemos rechazar la hipótesis nula y concluir que existe una asociación significativa entre las variables **cp** y **output**. Es decir, podemos afirmar que la distribución de la variable **cp** (tipo de dolor toráxico) difiere significativamente entre los grupos de **output**.

**thall** y **output**

```{r, warning=FALSE, message=FALSE}
prop.table(table(data$thall, data$output), margin = 1)
```

-   La tasa de salud es menor a la tasa de enfermedad cuando los pacientes poseen una prueba de esfuerzo con talio que indica un defecto fijo, la cual es de $22.02\%$.

-   Por otro lado, la tasa de salud es alta cuando los pacientes dan resultados normales o defectos reversibles, en este casos, la tasa de salud es $66.67\%$ y $76.07\%$, respectivamente.

Con la prueba $\chi^2$ se obtienen los siguientes resultados:

```{r, warning=FALSE, message=FALSE}
outputthall<- table(data$thall, data$output)
chisq.test(outputthall)
```

Para un nivel de significancia del $\alpha = 0.05$, dado que $p-valor < \alpha$, podemos rechazar la hipótesis nula y concluir que existe una asociación significativa entre las variables **thall** y **output**. Es decir, podemos afirmar que la distribución de la variable **thall** (resultados de prueba de esfuerzo con talio) difiere significativamente entre los grupos de **output**.

**restecg** y **output**

```{r, warning=FALSE, message=FALSE}
prop.table(table(data$restecg, data$output), margin = 1)
```

-   Cuando el paciente posee anomalías en la onda ST-T, la tasa de salud ($36.84\%$) es menor en comparación a la tasa de enfermedad ($63.16\%$).

La prueba $\chi^2$ nos indica los siguientes resultados:

```{r, warning=FALSE, message=FALSE}
outputrestecg<- table(data$restecg, data$output)
chisq.test(outputrestecg)
```

Para un nivel de significancia del $\alpha = 0.05$, dado que $p-valor < \alpha$, podemos rechazar la hipótesis nula y concluir que existe una asociación significativa entre las variables **restecg** y **output**. Es decir, podemos afirmar que la distribución de la variable **restecg** (resultados electrocardiográficos en reposo) difiere significativamente entre los grupos de **output**.

**exng** y **output**

```{r, warning=FALSE, message=FALSE}
prop.table(table(data$exng, data$output), margin = 1)
```

-   Si el paciente posee angina la tasa de salud ($76.77\%$) es mayor a la tasa de sufrir un ataque cardíaco ($23.23\%$).

Con la prueba $\chi^2$, obtenemos los siguientes resultados:

```{r, warning=FALSE, message=FALSE}
outputexng<- table(data$exng, data$output)
chisq.test(outputexng)
```

Para un nivel de significancia del $\alpha = 0.05$, dado que $p-valor < \alpha$, podemos rechazar la hipótesis nula y concluir que existe una asociación significativa entre las variables **exng** y **output**. Es decir, podemos afirmar que la distribución de la variable **exng** (angina producida por ejercicio) difiere significativamente entre los grupos de **output**.

**slp** y **output**

```{r, warning=FALSE, message=FALSE}
prop.table(table(data$slp, data$output), margin = 1)
```

-   Únicamente cuando la pendiente de un segmento de electrocardiograma del paciente es ascendente, la tasa de salud ($24.65\%$) es menor a la tasa de enfermedad ($75.35\%$).

-   Cuando los pacientes tienen pendiente descendente o pendiente normal, entonces sus tasas de salud son mayores, siendo estás de $57.14\%$ y $65\%$, respectivamente.

La prueba $\chi^2$ no permite obtener los siguientes resultados:

```{r, warning=FALSE, message=FALSE}
outputslp<- table( data$slp, data$output)
chisq.test(outputslp)
```

Si consideramos un nivel de significancia del $\alpha = 0.05$, dado que $p-valor < \alpha$, podemos rechazar la hipótesis nula y concluir que existe una asociación significativa entre las variables **slp** y **output**. Es decir, podemos afirmar que la distribución de la variable **slp** (Pendiente de un segmento de electrocardiograma) difiere significativamente entre los grupos de **output**.

**fbs** y **output**

```{r, warning=FALSE, message=FALSE}
prop.table(table(data$fbs, data$output), margin = 1)
```

-   En ambas categorías la tasa de salud es menor a la tasa de enfermedad.

Aplicando la prueba $\chi^2$, se obtiene que:

```{r, warning=FALSE, message=FALSE}
outputfbs<- table(data$fbs, data$output)
chisq.test(outputfbs)
```

Si consideramos un nivel de significancia del $\alpha = 0.05$, dado que $p-valor > \alpha$, no podemos rechazar la hipótesis nula, por lo cual, no existe una asociación significativa entre las variable **fbs** y **output**.

# Regresión logística

En el apartado anterior realizamos un análisis bivariado entre las variables numéricas y las variables categóricas con respecto a la variable **ouput**, por lo cual, en esta sección vamos a presentar un modelo de clasificación con la intención de predecir la probabilidad de que una persona sea más propensa a sufrir un ataque cardíaco, para ello, vamos a utilizar una regresión logística.

En primer lugar, vamos a divir el conjunto de datos de modo que el $80\%$ corresponda a la muestra de entrenamiento y el $20\%$ a la muestra de validación, para ello, emplearemos la *librería caret* y la *función createDataPartition()*:

```{r, warning=FALSE, message=FALSE}
library(caret)
## Fijamos el semillero
set.seed(1234)
# Dividimos los datos: 
indice <- createDataPartition(data$output, p = 0.8, list=FALSE)
training <- data[indice,]
val <- data[-indice,]
```

Verificamos que se mantenga la misma proporción de pacientes propensos y menos propensos a sufrir un ataque cardíaco en ambas muestras:

```{r}
training %>% count(output) %>%
        mutate(Percent = round(100*n / sum(n), 2)) %>%
        kable() %>% kable_material_dark(full_width = F)
```

Mientras que para la muestra de validación se tiene que:

```{r}
val %>% count(output) %>%
        mutate(Percent = round(100*n / sum(n), 2)) %>%
        kable() %>% kable_material_dark(full_width = F)
```

Por lo cual, podemos notar que la variable **output** se encuentra distribuída proporcionalmente en ambas muestras.

## Selección de variables

En los modelos logit, la prueba para contrastar las hipótesis si los coeficientes son diferentes de cero $(\beta_i\neq0)$ es la prueba de Wald.

Consideremos:

$$\begin{align*}
    H_0: \hat{\beta}_j & = \beta_{j0}, \\
    H_a: \hat{\beta}_j & \neq \beta_{j0}. 
\end{align*}$$

Bajo la hipótesis nula, el estadístico de Wald sigue una distribución $\chi^2$, y se define por: $$
    T = \frac{(\hat{\beta}_j-\beta_{j0})^{2}}{V[\hat{\beta}_j]}
$$

Para seleccionar los predictores que deben formar parte del modelo, emplearemos el método backward, este método primero calcula el modelo con todas las variables disponibles, luego se excluyen las variables una a una buscando una mejoría para finalmente eliminar la peor variable. Este método permite evaluar cada variable en presencia de las otras.

Para seleccionar los parámetros del modelo logit emplearemos el criterio de Akaike, que propone estudiar el problema de la identificación desde la perspectiva de la teoría de decisión estadística, que consiste en elegir como función de pérdida (o criterio de especificación) el AIC (Akaike Information Criterion) mínimo. Este valor se calcula por:

$$
    AIC = -2ln( \text{ máxima verosimilitud} ) + 2(\text{ no. de parámetros independientemente ajustados}). 
$$

Previo a aplicar el modelo, vamos a transformar las variables categóricas a dummy's, para ello, vamos a emplear la *librería fastDummies*:

```{r, warning=FALSE, message=FALSE}
library(fastDummies)
training<- training %>% dummy_cols(select_columns = c("sex","cp","fbs","restecg","exng","slp","thall" ), remove_selected_columns = T )
```

Aplicamos el modelo con todas las variables y luego consideramos el método backward para seleccionar las variables que formarán parte del modelo final:

```{r, warning=FALSE, message=FALSE}
logit<- glm(output~., data = training, family='binomial')
summary(logit)
```

Se puede encontrar variables no significativas cuyo p-valor es mayor a $0.05$, por lo tanto, hay que estimar un nuevo modelo.

```{r, warning=FALSE, message=FALSE, eval=FALSE}
step(logit, direction = "backward")
```

De este modo, consideramos el siguiente modelo:

```{r, warning=FALSE, message=FALSE}
logitFinal<- glm(formula = output ~ chol + thalachh + oldpeak + caa + sex_0 + 
    cp_0 + restecg_1 + thall_2, family = "binomial", data = training)

summary(logitFinal)
```

El valor de $AIC$ para este modelo es de $187.3$. Para intepretar los coeficientes obtenidos vamos a emplear los odd ratios:

```{r, warning=FALSE, message=FALSE}
odds<- exp(coefficients(logitFinal))
odds
```

De este modo, vamos a intepretar el coeficiente de cada una de las variables, mientras el resto se mantienen constantes:

-   **Intercepto**: Por el signo del coeficiente podemos asegurar que hay menos personas propensas a sufrir un ataque cardíaco. De hecho, existen $1.93$ pacientes propensos a sufrir un ataque cardíaco por cada persona que no es propensa.

-   **chol**: La probabilidad de que un paciente sea propenso a sufrir un ataque cardíaco está negativamente relacionada con la cantidad de colesterol del paciente. Por cada unidad que se reste de esta variable la probabilidad de tener un ataque cardíaco aumenta en promedio $1.009$ veces.

-   **thalachh**: La probabilidad de que un paciente sea propenso a sufrir un ataque cardíaco está positivamente relacionada con la frecuencia cardíaca máxima alcanzada. Por cada unidad que se aumente de esta variable la probabilidad de tener un ataque cardíaco aumenta en promedio $1.02$.

-   **oldpeak**: La probabilidad de que un paciente sea propenso a sufrir un ataque cardíaco está negativamente relacionada con la depresión del ST inducida por el ejercicio en relación con el reposo. Por cada unidad que se reste de esta variable la probabilidad de tener un ataque cardíaco aumenta en promedio $2.12$ veces.

-   **caa**: La probabilidad de que un paciente sea propenso a sufrir un ataque cardíaco está negativamente relacionada con el número de vasos principales coloreados por fluroscopia. Por cada unidad que se reste de esta variable la probabilidad de tener un ataque cardíaco aumenta en promedio $2.2$ veces.

-   **sex**: Cuando el paciente es mujer ($sex = 0$) la probabilidad de sufrir un ataque cardíaco es de $3.17$ veces mayor que cuando el paciente es hombre.

-   **cp**: Cuando el paciente es asintomático $cp = 0$, la probabilidad de sufrir un ataque cardíaco es $5.2$ veces menor que aquellos pacientes que poseen angina típica, angina atípica o dolor no anginoso.

-   **restecg**: Cuando el paciente presenta anomalías en la onda ST-T $restecg = 1$, la probabilidad de sufrir un ataque cardíaco es $2.65$ veces mayor que aquellos pacientes cuyos resultados fueron normales o que presentan hipertrofia ventricular izquierda.

-   **thall**: Cuando la prueba de esfuerzo con talio indica qye el paciente posee un defecto fijo $thall=2$, la probabilidad de sufrir un ataque cardíaco es $3.36$ veces mayor que aquellos clientes que obtuvieron defectos reversibles o resultados normales.

Para determinar el punto de corte y clasificar a los pacientes vamos a determinar la medida de Kolmogorov - Smirnov, de este, modo presentamos el gráfico de las distribuciones acumuladas de la razón de verdaderos positivos y la distribución de falsos positivos:

```{r, warning=FALSE, message=FALSE, fig.align='center'}
library(ROCit) 

val<- val %>% dummy_cols(select_columns = c("sex","cp","fbs","restecg","exng","slp","thall" ), remove_selected_columns = T )

dres <-data.frame(pred=predict(logitFinal, val, type="response"), var=val$output)

ROC <-rocit(score=dres$pred ,class=dres$var)

ksplot <-ksplot(ROC)

cutoff <-ksplot$'KS Cutoff'

kstat <-as.numeric(ksplot$'KS stat')
```

De este modo, el valor del $KS$ es `r kstat`, el cual se alcanza en `r cutoff`. Por lo cual, vamos a clasificar como pacientes propensos a sufrir un ataque cardíaco aquellos pacientes cuya probabilidad sea mayor a `r cutoff`. De este modo, presentamos la matriz de confusión:

```{r, warning=FALSE, message=FALSE}

val<- val %>% mutate(PREDICHO = predict(logitFinal, val, type="response"), 
                     PREDICCION = as.factor(ifelse(PREDICHO > cutoff , 1, 0)))


matrizConfusionVal<- confusionMatrix(val$PREDICCION, val$output, positive = "1")
matrizConfusionVal
```

De este modo, el modelo tiene una exactitud del $83.05\%$\`, una precisión de $86.67\%$ y un $F_1-score$ del $83.87\%$.

Ahora, vamos a calcular el valor del área bajo la curva $AUC$, para ello, consideremos la curva ROC:

```{r, warning=FALSE, message=FALSE, fig.align='center'}
library(plotROC)
library(ggExtra)


g1<-ggplot(val,aes(d=if_else(output == "1", 1, 0 ) ,m=PREDICHO))+ geom_roc()

logroc <-ggplot(val,aes(d = if_else(output == "1", 1, 0 ) ,m = PREDICHO)) + theme_bw() + geom_roc(n.cuts=0, colour="black") +theme(axis.text=element_text(colour ="blue"),
                                            plot.title = element_text(hjust = 0.5))+scale_x_continuous("\n1 - Especifidad",breaks=seq(0, 1, by = .2)) + scale_y_continuous("Sensibilidad \n",
                     breaks = seq(0, 1, by = .2)) +
  geom_abline(intercept=0, slope=1,
              colour="green", linetype="dashed") +
  annotate("text", x=0.6, y=0.45,  parse=TRUE ,
           label=paste0("AUC: ",round(calc_auc(g1)$AUC ,3)),
           colour="green")+ggExtra::removeGridX ()+
  ggExtra::removeGridY ()

logroc

```

Con lo cual, obtenemos un valor de $AUC = 0.92$.

Finalmente, para detectar la multicolinealidad emplearemos el **Factor de Inflación de la Varianza Generalizado (GVIF)** de los parámetros estimados, el cual proporciona un índice que mide hasta que punto la varianza de un coeficiente de regresión estimado se incrementa a causa de la colinealidad; Los valores de los GVIF calculados de cada variable no deben ser mayores a 4

```{r, warning=FALSE, message=FALSE}
car::vif(logitFinal)
```

Podemos notar que para ninguna variable el valor del $GVIF$ es superior a $4$, por lo cual, podemos concluir que no existen problemas de multicolinealidad.

# Conclusiones
